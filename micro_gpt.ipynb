{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "938bb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9cb5874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13b8d0fbb5d4d48888683c9ffdfe59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 93.6k/93.6k [00:00<00:00, 376kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef8f773b2834fb7a107856f986c3d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"zhyncs/sonnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46ba32",
   "metadata": {},
   "source": [
    "## Andrej uses a names dataset, but I will explore sonnet generation instead\n",
    "\n",
    "The task will be to generate (possibly Shakespearean-style) sonnets.\n",
    "\n",
    "## Tokenization\n",
    "\n",
    "There are a few approahces for tokenization. BPE is the real algorithm an LLm uses. For efficiency (and simplicity) in MicroGPT, I will use character-based tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c603c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69799340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Love's fire heats water, water cools not love.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247dd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = set()\n",
    "\n",
    "for row in train_ds:\n",
    "  chars_list = list(row['text'])\n",
    "  for c in chars_list:\n",
    "    unique_chars.add(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a911bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 59\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size\n",
    "print(\"Vocab size:\", len(unique_chars))\n",
    "\n",
    "## Now convert this list of chars to a proper vocabulary\n",
    "## char_id -> char\n",
    "vocab = {index: char for index, char in enumerate(unique_chars)}\n",
    "\n",
    "## The tokenizer does the opposite: go from text to integers\n",
    "tokenizer = {char: index for index, char in enumerate(unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3c4534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'X',\n",
       " 1: 'M',\n",
       " 2: 'B',\n",
       " 3: 'b',\n",
       " 4: 'a',\n",
       " 5: 'C',\n",
       " 6: 'F',\n",
       " 7: 'u',\n",
       " 8: 'T',\n",
       " 9: 'A',\n",
       " 10: '!',\n",
       " 11: 'r',\n",
       " 12: 'i',\n",
       " 13: ',',\n",
       " 14: 'E',\n",
       " 15: 'w',\n",
       " 16: 'z',\n",
       " 17: 'P',\n",
       " 18: 'm',\n",
       " 19: ':',\n",
       " 20: 's',\n",
       " 21: 'R',\n",
       " 22: 'N',\n",
       " 23: 'L',\n",
       " 24: 'G',\n",
       " 25: 'V',\n",
       " 26: 'K',\n",
       " 27: 'j',\n",
       " 28: 'h',\n",
       " 29: 'y',\n",
       " 30: ' ',\n",
       " 31: 'J',\n",
       " 32: 'q',\n",
       " 33: 'D',\n",
       " 34: ';',\n",
       " 35: 'n',\n",
       " 36: \"'\",\n",
       " 37: 'f',\n",
       " 38: '-',\n",
       " 39: 'O',\n",
       " 40: 'x',\n",
       " 41: 'o',\n",
       " 42: 'U',\n",
       " 43: 'p',\n",
       " 44: 't',\n",
       " 45: 'v',\n",
       " 46: 'I',\n",
       " 47: 'W',\n",
       " 48: 'Y',\n",
       " 49: 'l',\n",
       " 50: 'S',\n",
       " 51: 'g',\n",
       " 52: 'c',\n",
       " 53: 'd',\n",
       " 54: '.',\n",
       " 55: 'k',\n",
       " 56: 'e',\n",
       " 57: '?',\n",
       " 58: 'H'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9ea8f",
   "metadata": {},
   "source": [
    "## Build Autograd Now\n",
    "\n",
    "We want all basic operations in the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "25103905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "  def __init__(self, val : float, name=\"\", op=\"\", children=[]):\n",
    "    self.val = val\n",
    "    self.name = name\n",
    "    self.children = children # should be ordered, not sets!\n",
    "    self.local_grads = [] # local gradient of current node wrt children\n",
    "    self.grad = 0 # total gradient (add to this)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return {self.val}\n",
    "  \n",
    "  def __str__(self):\n",
    "    return (f\"{self.name}: {self.val}\")\n",
    "\n",
    "\n",
    "  # Overrie original add function for Value object\n",
    "  def __add__(self, other, op=\"+\", other_name=None):\n",
    "    if not isinstance(other, Value):\n",
    "      other = Value(other)\n",
    "    new_val = Value(self.val + other.val, children=set([self, other]))\n",
    "    new_val.local_grads = [1,1]\n",
    "    return new_val\n",
    "  \n",
    "  def __neg__(self):\n",
    "    new_val = Value(-self.val, children=[self])\n",
    "    new_val.local_grads = [-1]\n",
    "    return new_val\n",
    "  \n",
    "  def __sub__(self, other):\n",
    "    return self.__add__((-other), other_name= other.name)\n",
    "  \n",
    "  def __mul__(self, other, other_name=None):\n",
    "    new_val = Value(self.val * other.val, children=set([self, other]))\n",
    "    new_val.local_grads = [other.val, self.val]\n",
    "    return new_val\n",
    "  \n",
    "  def __pow__(self, exp : float, op=\"^\"):\n",
    "    new_val = Value(self.val ** exp, children=[self])\n",
    "    new_val.local_grads = [exp * self.val ** (exp - 1)]\n",
    "    return new_val\n",
    "  \n",
    "  def __truediv__(self, other, op=\"/\"):\n",
    "    denom = other ** (-1)\n",
    "    new_val = Value(self.val * denom.val, children=[self, other])\n",
    "    new_val.local_grads = [-1 / denom.val, self.val / (denom.val * denom.val)]\n",
    "    return new_val\n",
    "  \n",
    "  def exp(self):\n",
    "    new_val = Value(math.exp(self.val), children=[self])\n",
    "    new_val.local_grads = [math.exp(self.val)]\n",
    "    return new_val\n",
    "  \n",
    "  def log(self):\n",
    "    new_val = Value(math.log(self.val), children=[self])\n",
    "    new_val.local_grads = [1 / self.val]\n",
    "    return new_val\n",
    "  \n",
    "  def relu(self):\n",
    "    new_val = Value(max(0, self.val), children=[self])\n",
    "    new_val.local_grads = [float(self.val > 0)]\n",
    "    return new_val\n",
    "  \n",
    "  def backward(self):\n",
    "    # compute the gradient from the root\n",
    "    topo = []\n",
    "    visited = set()\n",
    "    # first construct a topsort of the computational graph\n",
    "    def construct_toposort(cur):\n",
    "      if cur not in visited:\n",
    "        visited.add(cur)\n",
    "        for n in cur.children:\n",
    "          construct_toposort(n)\n",
    "        topo.append(cur)\n",
    "    \n",
    "    construct_toposort(self)\n",
    "    self.grad = 1\n",
    "    for v in reversed(topo):\n",
    "      for child, local_grads in zip(v.children, v.local_grads):\n",
    "        child.grad += local_grads * v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "641f6c65",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__repr__ returned non-string (type set)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/core/formatters.py:770\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    764\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    766\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    767\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    768\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    769\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 770\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/lib/pretty.py:419\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    410\u001b[0m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    411\u001b[0m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    418\u001b[0m                 ):\n\u001b[0;32m--> 419\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.10/site-packages/IPython/lib/pretty.py:794\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 794\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "\u001b[0;31mTypeError\u001b[0m: __repr__ returned non-string (type set)"
     ]
    }
   ],
   "source": [
    "inf = Value(float('-inf'))\n",
    "inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3c04a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(5, \"a\")\n",
    "b = Value(3, \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "23afa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b\n",
    "d = c**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0617d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8876af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4e1ae69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c8e4dac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "245581a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "54cb22a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4045663001.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[210], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    so grad(d) = 1\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "b = 3\n",
    "c = a + b # 8\n",
    "d = c^3\n",
    "\n",
    "so grad(d) = 1\n",
    "grad (c) = 3 c^2\n",
    "grad(b) = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f53c0e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "2.0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = Value(2.0)\n",
    "b = Value(3.0)\n",
    "c = a * b       # c = 6.0\n",
    "L = c + a       # L = 8.0\n",
    "L.backward()\n",
    "print(a.grad)   # 4.0 (dL/da = b + 1 = 3 + 1, via both paths)\n",
    "print(b.grad)   # 2.0 (dL/db = a = 2)\n",
    "print(c.grad)   \n",
    "print(L.grad)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc58c223",
   "metadata": {},
   "source": [
    "## Now that AutoGrad is working, can actually define our model!\n",
    "\n",
    "This won't be too big of a model (just overfit to sonnets), so will have:\n",
    "- embedding dimension: 16\n",
    "- attention heads: 4\n",
    "- layers: 1\n",
    "- block size: 16 # max sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "40a5b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 16\n",
    "attn_heads = 4\n",
    "layers = 1\n",
    "block_size = 16\n",
    "hidden_dim = int(embed_dim / attn_heads) # dimension of each head\n",
    "# define some matrix\n",
    "vocab_size = len(vocab)\n",
    "def create_matrix(in_dim, out_dim, std=0.08):\n",
    "  # creates a matrix of size in_dim x out_dim\n",
    "  return [[Value(random.gauss(0, std)) for _ in range(out_dim)] for _ in range(in_dim)]\n",
    "\n",
    "state_dict = {}\n",
    "for i in range(layers):\n",
    "  # Projects embedding -> Query vectors\n",
    "  state_dict[f'layer_{i}_attn_wq'] = create_matrix(embed_dim, embed_dim)\n",
    "  # Projects embedding -> Key vectors\n",
    "  state_dict[f'layer_{i}_attn_wk'] = create_matrix(embed_dim, embed_dim)\n",
    "  # Projects embedding -> Value vectors\n",
    "  state_dict[f'layer_{i}_attn_wv'] = create_matrix(embed_dim, embed_dim)\n",
    "  # Final projection after concatenating all heads.\n",
    "  state_dict[f'layer_{i}_attn_wo'] = create_matrix(embed_dim, embed_dim)\n",
    "  # Standard MLP: Linear(embed_dim -> 4*embed_dim); GELU; Linear(4*embed_dim -> embed_dim)\n",
    "  state_dict[f'layer_{i}_fc1'] = create_matrix(embed_dim, 4 * embed_dim)\n",
    "  state_dict[f'layer_{i}_fc2'] = create_matrix(4 * embed_dim, embed_dim)\n",
    "\n",
    "# Used to map final hidden state -> logits over vocabulary:\n",
    "state_dict[f'output_head'] = create_matrix(embed_dim, vocab_size)\n",
    "# This is positional embedding\n",
    "state_dict[f'pos_embedding'] = create_matrix(block_size, embed_dim)\n",
    "# this is token embedding\n",
    "state_dict[f'token_embedding'] = create_matrix(vocab_size, embed_dim)\n",
    "\n",
    "params = [p for mat in state_dict.values() for row in mat for p in row]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2693efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA:\n",
    "  def __init__(self, wq, wk, wv, wo, config):\n",
    "    self.wq = wq\n",
    "    self.wk = wk\n",
    "    self.wv = wv\n",
    "    self.wo = wo\n",
    "    self.config = config\n",
    "  \n",
    "  def forward(self, input, attn_mask):\n",
    "    attn_weights = (self.wq @ self.wk.T) / math.sqrt(self.config.hidden_dim)\n",
    "\n",
    "    \n",
    "\n",
    "    masked_attn_weights = attn_weights +  attn_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "1ea26282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(W, x):\n",
    "  return [sum((w_i * x_i for w_i, x_i in zip(w_row, x)), Value(0.0)) for w_row in W]\n",
    "\n",
    "def softmax(input):\n",
    "  denom = sum([Value.exp(x) for x in input])\n",
    "  logits = [Value.exp(x) / denom for x in input]\n",
    "  return logits\n",
    "\n",
    "def rmsnorm(x):\n",
    "  ms = sum((xi * xi for xi in x), Value(0.0)) / Value(float(len(x)))\n",
    "  scale = (ms + 1e-5) ** -0.5\n",
    "  return [xi * scale for xi in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "8e474d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = [[Value(float('-inf')) for _ in range(hidden_dim)] for _ in range(hidden_dim)]\n",
    "for i in range(hidden_dim):\n",
    "  for j in range(i):\n",
    "    attn_mask[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "802e57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(dim, i):\n",
    "  output = [Value(0) for _ in range(dim)]\n",
    "  output[i] = 1\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a517dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt(token_id, pos_id, keys, values): # add attention mask?\n",
    "  # one_hot_token_id = one_hot(vocab_size, token_id)\n",
    "  # token_emb = linear(state_dict[f'token_embedding'], one_hot_token_id)\n",
    "\n",
    "  # one_hot_pos_id = one_hot(block_size, pos_id)\n",
    "  # pos_emb = linear(state_dict[f'pos_embedding'], one_hot_pos_id)\n",
    "\n",
    "  token_emb = state_dict['token_embedding'][token_id]\n",
    "  pos_emb = state_dict['pos_embedding'][pos_id]\n",
    "  embedding = token_emb + pos_emb\n",
    "  embedding = rmsnorm(embedding)\n",
    "\n",
    "  input = embedding\n",
    "  output = None\n",
    "  for i in range(layers):\n",
    "    residual = input\n",
    "    # MHA\n",
    "    Q = linear(state_dict[f'layer_{i}_attn_wq'], input)\n",
    "    K = linear(state_dict[f'layer_{i}_attn_wk'], input)\n",
    "    V = linear(state_dict[f'layer_{i}_attn_wv'], input)\n",
    "\n",
    "    keys.append(K)\n",
    "    values.append(V)\n",
    "\n",
    "    x_attn = []\n",
    "    for h in range(attn_heads):\n",
    "      hs = h * hidden_dim\n",
    "      q_h = Q[hs: hs + hidden_dim]\n",
    "      k_h = [ki[hs: hs + hidden_dim] for ki in keys[i]]\n",
    "      v_h = [vi[hs: hs + hidden_dim] for vi in values[i]]\n",
    "      attn_logits = [sum(q_h[j] * k_h[t][j] for j in range(hidden_dim)) / math.sqrt(hidden_dim) for t in range(len(k_h))]\n",
    "      attn_weights = softmax(attn_logits)\n",
    "      head_out = [sum(attn_weights[i] * v_h[t][j] for t in range(len(v_h))) for j in range(hidden_dim)]\n",
    "\n",
    "      x_attn.extend(head_out)\n",
    "\n",
    "    \n",
    "    x_proj = linear(state_dict[f'layer_{i}_attn_wo'], x_attn)\n",
    "    x = [x_i + r for x_i, r in zip(x_proj, residual)]\n",
    "    x_residual = x\n",
    "    x = rmsnorm(x)\n",
    "\n",
    "    ## Feed Forward\n",
    "\n",
    "    l1 =  linear(state_dict[f'layer_{i}_fc1'], x)\n",
    "    l1_relu = [x.relu() for x in l1]\n",
    "    l2 = linear(state_dict[f'layer_{i}_fc1'], l1_relu)\n",
    "    x = l2 + x_residual\n",
    "\n",
    "    input = x\n",
    "    output = x\n",
    "\n",
    "  logits = linear(state_dict['output_head'], output)\n",
    "  return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c969de5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[307], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(token_id)\n\u001b[1;32m     20\u001b[0m token_id, target_id \u001b[38;5;241m=\u001b[39m tokens[pos_id], tokens[pos_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mgpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m probs \u001b[38;5;241m=\u001b[39m softmax(logits)\n\u001b[1;32m     23\u001b[0m loss_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mprobs[target_id]\u001b[38;5;241m.\u001b[39mlog() \u001b[38;5;66;03m# cross entropy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[306], line 38\u001b[0m, in \u001b[0;36mgpt\u001b[0;34m(token_id, pos_id, keys, values)\u001b[0m\n\u001b[1;32m     33\u001b[0m   head_out \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28msum\u001b[39m(attn_weights[i] \u001b[38;5;241m*\u001b[39m v_h[t][j] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(v_h))) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hidden_dim)]\n\u001b[1;32m     35\u001b[0m   x_attn\u001b[38;5;241m.\u001b[39mextend(head_out)\n\u001b[0;32m---> 38\u001b[0m x_proj \u001b[38;5;241m=\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_attn_wo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_attn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m [x_i \u001b[38;5;241m+\u001b[39m r \u001b[38;5;28;01mfor\u001b[39;00m x_i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(x_proj, residual)]\n\u001b[1;32m     40\u001b[0m x_residual \u001b[38;5;241m=\u001b[39m x\n",
      "Cell \u001b[0;32mIn[295], line 2\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(W, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlinear\u001b[39m(W, x):\n\u001b[0;32m----> 2\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28msum\u001b[39m((w_i \u001b[38;5;241m*\u001b[39m x_i \u001b[38;5;28;01mfor\u001b[39;00m w_i, x_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(w_row, x)), Value(\u001b[38;5;241m0.0\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m w_row \u001b[38;5;129;01min\u001b[39;00m W]\n",
      "Cell \u001b[0;32mIn[295], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlinear\u001b[39m(W, x):\n\u001b[0;32m----> 2\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w_row \u001b[38;5;129;01min\u001b[39;00m W]\n",
      "Cell \u001b[0;32mIn[295], line 2\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlinear\u001b[39m(W, x):\n\u001b[0;32m----> 2\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28msum\u001b[39m((\u001b[43mw_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_i\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w_i, x_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(w_row, x)), Value(\u001b[38;5;241m0.0\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m w_row \u001b[38;5;129;01min\u001b[39;00m W]\n",
      "Cell \u001b[0;32mIn[267], line 33\u001b[0m, in \u001b[0;36mValue.__mul__\u001b[0;34m(self, other, other_name)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, other_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 33\u001b[0m   new_val \u001b[38;5;241m=\u001b[39m Value(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval \u001b[38;5;241m*\u001b[39m \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval\u001b[49m, children\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m([\u001b[38;5;28mself\u001b[39m, other]))\n\u001b[1;32m     34\u001b[0m   new_val\u001b[38;5;241m.\u001b[39mlocal_grads \u001b[38;5;241m=\u001b[39m [other\u001b[38;5;241m.\u001b[39mval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval]\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m new_val\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'val'"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "beta_1 = .85\n",
    "beta_2 = .99\n",
    "eps_adam = 1e-8\n",
    "\n",
    "steps = 1000\n",
    "\n",
    "m1 = [0 for _ in params]\n",
    "m2 = [0 for _ in params]\n",
    "\n",
    "for step in range(steps):\n",
    "  sonnet = train_ds[step]['text']\n",
    "  tokens = [tokenizer[c] for c in list(sonnet)]\n",
    "  n = min(block_size, len(tokens) - 1)\n",
    "\n",
    "  keys, values = [[] for _ in range(layers)], [[] for _ in range(layers)]\n",
    "  losses = []\n",
    "  for pos_id in range(n):\n",
    "    print(token_id)\n",
    "    token_id, target_id = tokens[pos_id], tokens[pos_id + 1]\n",
    "    logits = gpt(token_id, pos_id, keys, values)\n",
    "    probs = softmax(logits)\n",
    "    loss_t = -probs[target_id].log() # cross entropy\n",
    "    losses.append(loss_t)\n",
    "\n",
    "  loss = (1/n) * sum(losses)\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  lr_t = lr * (1 - step / steps)\n",
    "  for i, p in enumerate(params):\n",
    "    m1[i] = beta_1 * m1[i] + (1 - beta_1) * p.grad\n",
    "    m2[i] = beta_2 * m2[i] + (1 - beta_2) * p.grad ** 2\n",
    "\n",
    "    m1_hat = m1[i] / (1 - beta_1 ** (step + 1))\n",
    "    m2_hat = m2[i] / (1 - beta_2 ** (step + 1))\n",
    "\n",
    "    p.data -= lr_t * m1_hat / (m2_hat ** 0.5 + eps_adam) ## fast update\n",
    "\n",
    "    p.grad = 0 # zero gradients at end \n",
    "\n",
    "  print(f\"step {step+1:4d} / {steps:4d} | loss {loss.data:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a87337b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334e8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
