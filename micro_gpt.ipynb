{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "938bb967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9cb5874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13b8d0fbb5d4d48888683c9ffdfe59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 93.6k/93.6k [00:00<00:00, 376kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef8f773b2834fb7a107856f986c3d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"zhyncs/sonnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46ba32",
   "metadata": {},
   "source": [
    "## Andrej uses a names dataset, but I will explore sonnet generation instead\n",
    "\n",
    "The task will be to generate (possibly Shakespearean-style) sonnets.\n",
    "\n",
    "## Tokenization\n",
    "\n",
    "There are a few approahces for tokenization. BPE is the real algorithm an LLm uses. For efficiency (and simplicity) in MicroGPT, I will use character-based tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c603c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69799340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Love's fire heats water, water cools not love.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247dd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = set()\n",
    "\n",
    "for row in train_ds:\n",
    "  chars_list = list(row['text'])\n",
    "  for c in chars_list:\n",
    "    unique_chars.add(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a911bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 59\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size\n",
    "print(\"Vocab size:\", len(unique_chars))\n",
    "\n",
    "## Now convert this list of chars to a proper vocabulary\n",
    "## char_id -> char\n",
    "vocab = {index: char for index, char in enumerate(unique_chars)}\n",
    "\n",
    "## The tokenizer does the opposite: go from text to integers\n",
    "tokenizer = {char: index for index, char in enumerate(unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3c4534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'X',\n",
       " 1: 'M',\n",
       " 2: 'B',\n",
       " 3: 'b',\n",
       " 4: 'a',\n",
       " 5: 'C',\n",
       " 6: 'F',\n",
       " 7: 'u',\n",
       " 8: 'T',\n",
       " 9: 'A',\n",
       " 10: '!',\n",
       " 11: 'r',\n",
       " 12: 'i',\n",
       " 13: ',',\n",
       " 14: 'E',\n",
       " 15: 'w',\n",
       " 16: 'z',\n",
       " 17: 'P',\n",
       " 18: 'm',\n",
       " 19: ':',\n",
       " 20: 's',\n",
       " 21: 'R',\n",
       " 22: 'N',\n",
       " 23: 'L',\n",
       " 24: 'G',\n",
       " 25: 'V',\n",
       " 26: 'K',\n",
       " 27: 'j',\n",
       " 28: 'h',\n",
       " 29: 'y',\n",
       " 30: ' ',\n",
       " 31: 'J',\n",
       " 32: 'q',\n",
       " 33: 'D',\n",
       " 34: ';',\n",
       " 35: 'n',\n",
       " 36: \"'\",\n",
       " 37: 'f',\n",
       " 38: '-',\n",
       " 39: 'O',\n",
       " 40: 'x',\n",
       " 41: 'o',\n",
       " 42: 'U',\n",
       " 43: 'p',\n",
       " 44: 't',\n",
       " 45: 'v',\n",
       " 46: 'I',\n",
       " 47: 'W',\n",
       " 48: 'Y',\n",
       " 49: 'l',\n",
       " 50: 'S',\n",
       " 51: 'g',\n",
       " 52: 'c',\n",
       " 53: 'd',\n",
       " 54: '.',\n",
       " 55: 'k',\n",
       " 56: 'e',\n",
       " 57: '?',\n",
       " 58: 'H'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9ea8f",
   "metadata": {},
   "source": [
    "## Build Autograd Now\n",
    "\n",
    "We want all basic operations in the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "25103905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "  def __init__(self, val : float, name=\"\", op=\"\", children=[]):\n",
    "    self.val = val\n",
    "    self.name = name\n",
    "    self.children = children # should be ordered, not sets!\n",
    "    self.local_grads = [] # local gradient of current node wrt children\n",
    "    self.grad = 0 # total gradient (add to this)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return (f\"{self.name}: {self.val}\")\n",
    "\n",
    "  # Overrie original add function for Value object\n",
    "  def __add__(self, other, op=\"+\", other_name=None):\n",
    "    if not other_name:\n",
    "      other_name = other.name\n",
    "\n",
    "    new_val = Value(self.val + other.val, name=f\"({self.name} {op} {other_name})\", children=set([self, other]))\n",
    "    new_val.local_grads = [1,1]\n",
    "    return new_val\n",
    "  \n",
    "  def __neg__(self):\n",
    "    new_val = Value(-self.val, name=f\"(-{self.name})\", children=[self])\n",
    "    new_val.local_grads = [-1]\n",
    "    return new_val\n",
    "  \n",
    "  def __sub__(self, other):\n",
    "    return self.__add__((-other), op=\"-\", other_name= other.name)\n",
    "  \n",
    "  def __mul__(self, other, op=\"*\", other_name=None):\n",
    "    if not other_name:\n",
    "      other_name = other.name\n",
    "    \n",
    "    new_val = Value(self.val * other.val, name=f\"({self.name} {op} {other_name})\", children=set([self, other]))\n",
    "    new_val.local_grads = [other.val, self.val]\n",
    "    return new_val\n",
    "  \n",
    "  def __pow__(self, exp : float, op=\"^\"):\n",
    "    new_val = Value(self.val ** exp, children=[self])\n",
    "    new_val.local_grads = [exp * self.val ** (exp - 1)]\n",
    "    return new_val\n",
    "  \n",
    "  def __truediv__(self, other, op=\"/\"):\n",
    "    denom = other ** (-1)\n",
    "    new_val = Value(self.val * denom.val, children=[self, other])\n",
    "    new_val.local_grads = [-1 / denom.val, self.val / (denom.val * denom.val)]\n",
    "    return new_val\n",
    "  \n",
    "  def exp(self):\n",
    "    new_val = Value(math.exp(self.val), name=f\"exp({self.name})\", children=[self])\n",
    "    new_val.local_grads = [math.exp(self.val)]\n",
    "    return new_val\n",
    "  \n",
    "  def log(self):\n",
    "    new_val = Value(math.log(self.val), name=f\"log({self.name})\", children=[self])\n",
    "    new_val.local_grads = [1 / self.val]\n",
    "    return new_val\n",
    "  \n",
    "  def relu(self):\n",
    "    new_val = Value(max(0, self.val), name=f\"ReLU({self.name})\", children=[self])\n",
    "    new_val.local_grads = [float(self.val > 0)]\n",
    "    return new_val\n",
    "  \n",
    "  def backward(self):\n",
    "    # compute the gradient from the root\n",
    "    topo = []\n",
    "    visited = set()\n",
    "    # first construct a topsort of the computational graph\n",
    "    def construct_toposort(cur):\n",
    "      if cur not in visited:\n",
    "        visited.add(cur)\n",
    "        for n in cur.children:\n",
    "          construct_toposort(n)\n",
    "        topo.append(cur)\n",
    "    \n",
    "    construct_toposort(self)\n",
    "    self.grad = 1\n",
    "    for v in reversed(topo):\n",
    "      for child, local_grads in zip(v.children, v.local_grads):\n",
    "        child.grad += local_grads * v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "641f6c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ": -inf"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf = Value(float('-inf'))\n",
    "inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3c04a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(5, \"a\")\n",
    "b = Value(3, \"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "23afa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b\n",
    "d = c**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0617d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8876af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4e1ae69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c8e4dac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "245581a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "54cb22a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4045663001.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[210], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    so grad(d) = 1\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "b = 3\n",
    "c = a + b # 8\n",
    "d = c^3\n",
    "\n",
    "so grad(d) = 1\n",
    "grad (c) = 3 c^2\n",
    "grad(b) = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f53c0e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "2.0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = Value(2.0)\n",
    "b = Value(3.0)\n",
    "c = a * b       # c = 6.0\n",
    "L = c + a       # L = 8.0\n",
    "L.backward()\n",
    "print(a.grad)   # 4.0 (dL/da = b + 1 = 3 + 1, via both paths)\n",
    "print(b.grad)   # 2.0 (dL/db = a = 2)\n",
    "print(c.grad)   \n",
    "print(L.grad)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc58c223",
   "metadata": {},
   "source": [
    "## Now that AutoGrad is working, can actually define our model!\n",
    "\n",
    "This won't be too big of a model (just overfit to sonnets), so will have:\n",
    "- embedding dimension: 16\n",
    "- attention heads: 4\n",
    "- layers: 1\n",
    "- block size: 16 # max sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "40a5b9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 16\n",
    "atten_heads = 4\n",
    "layers = 1\n",
    "block_size = 16\n",
    "hidden_dim = int(embed_dim / atten_heads) # dimension of each head\n",
    "# define some matrix\n",
    "vocab_size = len(vocab)\n",
    "def create_matrix(in_dim, out_dim, std=0.08):\n",
    "  # creates a matrix of size in_dim x out_dim\n",
    "  return [[Value(random.gauss(0, std)) for _ in range(out_dim)] for _ in range(in_dim)]\n",
    "\n",
    "state_dict = {}\n",
    "for i in range(layers):\n",
    "  # Projects embedding -> Query vectors\n",
    "  state_dict[f'layer_{i}_attn_wq'] = create_matrix(embed_dim, embed_dim)\n",
    "  # Projects embedding -> Key vectors\n",
    "  state_dict[f'layer_{i}_attn_wk'] = create_matrix(embed_dim, embed_dim)\n",
    "  # Projects embedding -> Value vectors\n",
    "  state_dict[f'layer_{i}_attn_wv'] = create_matrix(embed_dim, embed_dim)\n",
    "  # Final projection after concatenating all heads.\n",
    "  state_dict[f'layer_{i}_attn_wo'] = create_matrix(embed_dim, embed_dim)\n",
    "  # Standard MLP: Linear(embed_dim -> 4*embed_dim); GELU; Linear(4*embed_dim -> embed_dim)\n",
    "  state_dict[f'layer_{i}_fc1'] = create_matrix(embed_dim, 4 * embed_dim)\n",
    "  state_dict[f'layer_{i}_fc2'] = create_matrix(4 * embed_dim, embed_dim)\n",
    "\n",
    "# Used to map final hidden state -> logits over vocabulary:\n",
    "state_dict[f'output_head'] = create_matrix(embed_dim, vocab_size)\n",
    "# This is positional embedding\n",
    "state_dict[f'pos_embedding'] = create_matrix(block_size, embed_dim)\n",
    "# this is token embedding\n",
    "state_dict[f'token_embedding'] = create_matrix(vocab_size, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2693efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHA:\n",
    "  def __init__(self, wq, wk, wv, wo, config):\n",
    "    self.wq = wq\n",
    "    self.wk = wk\n",
    "    self.wv = wv\n",
    "    self.wo = wo\n",
    "    self.config = config\n",
    "  \n",
    "  def forward(self, input, attn_mask):\n",
    "    attn_weights = (self.wq @ self.wk.T) / math.sqrt(self.config.hidden_dim)\n",
    "\n",
    "    \n",
    "\n",
    "    masked_attn_weights = attn_weights +  attn_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1ea26282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(input):\n",
    "  pass\n",
    "\n",
    "def softmax(input):\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8e474d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = [[Value(float('-inf')) for _ in range(hidden_dim)] for _ in range(hidden_dim)]\n",
    "for i in range(hidden_dim):\n",
    "  for j in range(i):\n",
    "    attn_mask[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517dfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
